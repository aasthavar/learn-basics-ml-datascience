{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download dataset from kaggle\n",
    "# %mkdir dataset\n",
    "# !pip install kaggle\n",
    "# !kaggle datasets download -d mlg-ulb/creditcardfraud -p dataset\n",
    "# !unzip dataset/creditcardfraud.zip -d dataset\n",
    "\n",
    "# # install dependencies\n",
    "# !pip install --quiet numpy pandas scikit-learn imblearn xgboost lightgbm\n",
    "# !pip install --quiet ydata-profiling ipywidgets\n",
    "# !pip install --quiet plotly \"nbformat>=4.2.0\" statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV, RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, classification_report,\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, average_precision_score,\n",
    "    log_loss, brier_score_loss, matthews_corrcoef,   \n",
    ")\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from imblearn.ensemble import (\n",
    "    EasyEnsembleClassifier, \n",
    "    RUSBoostClassifier, \n",
    "    BalancedBaggingClassifier, \n",
    "    BalancedRandomForestClassifier\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv(\"dataset/creditcard.csv\")\n",
    "\n",
    "# convert all column names to lower\n",
    "df.columns = [col.lower() for col in df.columns.tolist()]\n",
    "\n",
    "# put target class at the beginning\n",
    "target = df[\"class\"]\n",
    "df.drop(\"class\", axis=1, inplace=True)\n",
    "df.insert(loc=0, column=\"class\", value=target)\n",
    "\n",
    "# printing stuff\n",
    "print(f\"shape: {df.shape}\")\n",
    "print(f\"columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check count and dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check statistics of numerical cols \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick eda (takes ~ 3 to 4 mins)\n",
    "# keyword = \"train\"\n",
    "# profile = ProfileReport(df, title=f\"{keyword} dataset\")\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick visualize\n",
    "for col in df.columns:\n",
    "    fig = px.histogram(df, x=col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout distribution of target class\n",
    "temp = df[\"class\"].value_counts(normalize=True).to_frame()\n",
    "round(temp, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of target class\n",
    "temp = df[\"class\"].value_counts().reset_index(name=\"count\")\n",
    "fig = px.bar(temp, x=\"class\", y=\"count\",  text=\"count\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"non-fraud(class=0) vs fraud(class=1)\",\n",
    "    width=400, height=400,\n",
    ")\n",
    "fig.update_traces(width=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for time\n",
    "fig = px.histogram(\n",
    "    df, x=\"time\",\n",
    "    marginal=\"rug\",\n",
    "    barmode=\"stack\", facet_col=\"class\", color=\"class\", \n",
    "    # barmode=\"overlay\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for amount\n",
    "fig = px.histogram(\n",
    "    df, x=\"amount\",\n",
    "    marginal=\"rug\", \n",
    "    barmode=\"stack\", facet_col=\"class\", color=\"class\", \n",
    "    # barmode=\"overlay\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    # scale time and amount\n",
    "    robust_scaler = RobustScaler()\n",
    "    data[[\"scaled_time\", \"scaled_amount\"]] = robust_scaler.fit_transform(data[[\"time\", \"amount\"]])\n",
    "    \n",
    "    # drop time and amount\n",
    "    data.drop([\"time\", \"amount\"], axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(data=df)\n",
    "\n",
    "# printing stuff\n",
    "print(f\"shape: {df.shape}\")\n",
    "print(f\"columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(data):\n",
    "    FEATURES = [\"scaled_time\", \"scaled_amount\", \"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\", \"v10\", \"v11\", \"v12\", \"v13\", \"v14\", \"v15\", \"v16\", \"v17\", \"v18\", \"v19\", \"v20\", \"v21\", \"v22\", \"v23\", \"v24\", \"v25\", \"v26\", \"v27\", \"v28\"]\n",
    "    TARGET = \"class\"\n",
    "    \n",
    "    # X = data.drop(TARGET, axis=1)\n",
    "    X = data[FEATURES]\n",
    "    y = data[TARGET]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original X and y\n",
    "X, y = get_X_y(df)\n",
    "print(f\"Original:\")\n",
    "print(f\"X.shape: {X.shape} | y.shape: {y.shape}\")\n",
    "print(y.value_counts().reset_index())\n",
    "\n",
    "\n",
    "# sample\n",
    "random_us = RandomUnderSampler(random_state=1729, sampling_strategy=\"majority\")\n",
    "X_rus, y_rus = random_us.fit_resample(X, y)\n",
    "print(f\"\\nAfter Sampling:\")\n",
    "print(f\"X_rus.shape: {X_rus.shape} | y_rus.shape: {y_rus.shape}\")\n",
    "print(y_rus.value_counts().reset_index())\n",
    "\n",
    "\n",
    "# create dataframe\n",
    "df_rus = pd.concat([X_rus, y_rus], axis=1)\n",
    "print(f\"shape: {df_rus.shape}\")\n",
    "print(f\"columns: {df_rus.columns.tolist()}\")\n",
    "df_rus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of target class\n",
    "temp = df_rus[\"class\"].value_counts().reset_index(name=\"count\")\n",
    "fig = px.bar(temp, x=\"class\", y=\"count\",  text=\"count\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"non-fraud(class=0) vs fraud(class=1)\",\n",
    "    width=400, height=400,\n",
    ")\n",
    "fig.update_traces(width=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: data is already normalized - no need to repeat again!\n",
    "# correlation\n",
    "correlation = df.corr()\n",
    "\n",
    "# plot\n",
    "fig = px.imshow(\n",
    "    correlation.round(2),\n",
    "    text_auto=True, aspect=\"auto\", \n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    width=1400, height=1400,\n",
    ")\n",
    "fig.update_traces(textfont_size=8)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: data is already normalized - no need to repeat again!\n",
    "# correlation\n",
    "correlation = df_rus.corr()\n",
    "\n",
    "# plot\n",
    "fig = px.imshow(\n",
    "    correlation.round(2),\n",
    "    text_auto=True, aspect=\"auto\", \n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    width=1400, height=1400,\n",
    ")\n",
    "fig.update_traces(textfont_size=8)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df_rus.corr()[\"class\"].reset_index(name=\"value\").rename(columns={\"index\": \"column\"})\n",
    "corr_df = corr_df.drop(corr_df[corr_df[\"column\"] == \"class\"].index)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = corr_df[(corr_df.value > 0.2) | (corr_df.value < -0.5)]\n",
    "\n",
    "class_df.sort_values(by=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = class_df.column.to_list()\n",
    "\n",
    "titles = [f\"feature={feature}\" for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 2, 4\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows, cols=cols,\n",
    "    subplot_titles=titles,\n",
    "    vertical_spacing=0.15,\n",
    ")\n",
    "\n",
    "for r in range(1, rows+1):\n",
    "    for c in range(1, cols+1):\n",
    "        fig.add_trace(\n",
    "            go.Histogram(name=features[r+c-2], x=df_rus.loc[df_rus[\"class\"]==1, features[r+c-2]]),\n",
    "            r, c\n",
    "        )\n",
    "        fig.update_xaxes(mirror=True, linewidth=2, linecolor=\"black\", row=r, col=c)\n",
    "        fig.update_yaxes(mirror=True, linewidth=2, linecolor=\"black\", row=r, col=c)\n",
    "\n",
    "fig.update_layout(title=\"Feature Distributions for Fraud Transactions\", template=\"seaborn\",)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 2, 4\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows, cols=cols,\n",
    "    subplot_titles=titles,\n",
    "    vertical_spacing=0.15,\n",
    ")\n",
    "\n",
    "for r in range(1, rows+1):\n",
    "    for c in range(1, cols+1):\n",
    "        fig.add_trace(\n",
    "            go.Histogram(name=features[r+c-2], x=df_rus.loc[df_rus[\"class\"]==0, features[r+c-2]]),\n",
    "            r, c\n",
    "        )\n",
    "        fig.update_xaxes(mirror=True, linewidth=2, linecolor=\"black\", row=r, col=c)\n",
    "        fig.update_yaxes(mirror=True, linewidth=2, linecolor=\"black\", row=r, col=c)\n",
    "\n",
    "fig.update_layout(title=\"Feature Distributions for Non-Fraud Transactions\", template=\"seaborn\",)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_corr_cols = corr_df[corr_df.value > 0.2][\"column\"].tolist()\n",
    "pos_titles = [f\"feature={feature}\" for feature in pos_corr_cols]\n",
    "\n",
    "neg_corr_cols = corr_df[corr_df.value < -0.5][\"column\"].tolist()\n",
    "neg_titles = [f\"feature={feature}\" for feature in neg_corr_cols]\n",
    "\n",
    "print(f\"columns with positive correlations: {pos_corr_cols}\")\n",
    "print(f\"columns with negative correlations: {neg_corr_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for positive correlation\n",
    "rows, cols = 1,  4\n",
    "\n",
    "features = pos_corr_cols\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows, cols=cols,\n",
    "    subplot_titles=pos_titles,\n",
    "    vertical_spacing=0.15,\n",
    ")\n",
    "\n",
    "for r in range(1, rows+1):\n",
    "    for c in range(1, cols+1):\n",
    "        fig.add_trace(\n",
    "            go.Box(name=features[r+c-2], x=df_rus[\"class\"], y=df_rus[features[r+c-2]]),\n",
    "            r, c\n",
    "        )\n",
    "        fig.update_xaxes(mirror=True, linewidth=2, linecolor=\"black\", row=r, col=c)\n",
    "        fig.update_yaxes(mirror=True, linewidth=2, linecolor=\"black\", row=r, col=c)\n",
    "\n",
    "fig.update_layout(width=700, template=\"seaborn\", title=\"Boxplots for Positive Correlations\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for negative correlation\n",
    "rows, cols = 1, 4\n",
    "\n",
    "features = neg_corr_cols\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows, cols=cols, subplot_titles=neg_titles, vertical_spacing=0.15,\n",
    ")\n",
    "\n",
    "for r in range(1, rows+1):\n",
    "    for c in range(1, cols+1):\n",
    "        fig.add_trace(\n",
    "            go.Box(name=features[r+c-2], x=df_rus[\"class\"], y=df_rus[features[r+c-2]]),\n",
    "            r, c\n",
    "        )\n",
    "\n",
    "fig.update_layout(width=700, template=\"seaborn\", title=\"Boxplots for Negative Correlations\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(df, feature):\n",
    "    filtered_df = df[df[\"class\"] == 1][feature]\n",
    "    \n",
    "    # calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    q25, q75 = np.percentile(filtered_df, 25), np.percentile(filtered_df, 75)\n",
    "    \n",
    "    # calculate IQR and cutoff\n",
    "    iqr = q75 - q25\n",
    "    cutoff = iqr * 1.5\n",
    "    lower_threshold, upper_threshold = q25 - cutoff, q75 + cutoff\n",
    "    \n",
    "    # count outliers\n",
    "    outliers_count = np.sum((filtered_df < lower_threshold) | (filtered_df > upper_threshold))\n",
    "    \n",
    "    # remove outliers\n",
    "    df = df[~((df[feature] < lower_threshold) | (df[feature] > upper_threshold))]\n",
    "    \n",
    "    print(f\"feature: {feature} | outliers_count: {outliers_count} | count(records_after_outlier_removal): {len(df)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rus_rm_out = outlier_removal(df_rus, \"v10\")\n",
    "df_rus_rm_out = outlier_removal(df_rus_rm_out, \"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 2, 2\n",
    "\n",
    "features = [\"v2\", \"v10\"]\n",
    "titles = [\n",
    "    \"v2 vs class <br> (before outlier removal)\", \n",
    "    \"v2 vs class <br> (after outlier removal)\", \n",
    "    \"v10 vs class <br> (before outlier removal)\", \n",
    "    \"v10 vs class <br> (after outlier removal)\", \n",
    "]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows, cols=cols, shared_yaxes=True, subplot_titles=titles\n",
    ")\n",
    "\n",
    "for r in range(1, rows+1):\n",
    "    fig.add_trace(\n",
    "        go.Box(name=f\"{features[r-1]}(before)\", x=df_rus[\"class\"], y=df_rus[features[r-1]]),\n",
    "        r,1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Box(name=f\"{features[r-1]}(after)\", x=df_rus_out[\"class\"], y=df_rus_out[features[r-1]]),\n",
    "        r,2\n",
    "    )\n",
    "fig.update_layout(width=700, template=\"seaborn\", title=\"comparison of boxplots for v2 & v10\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    {\n",
    "        \"name\": \"logisticregression\",\n",
    "        \"clf\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"xgbclassifier\", # takes 15 mins\n",
    "        \"clf\": XGBClassifier(objective=\"binary:logistic\", random_state=1729),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 500, 1000],\n",
    "            \"max_depth\": [5, 10],\n",
    "            \"learning_rate\": [0.075, 0.1],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"randomforestclassifier\",\n",
    "        \"clf\": RandomForestClassifier(random_state=1729,),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 500], \n",
    "            \"max_depth\": [5, 10],\n",
    "            \"max_leaf_nodes\": [64, 128, 256],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gradientboostingclassifier\",\n",
    "        \"clf\": GradientBoostingClassifier(random_state=1729),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 500, 1000],\n",
    "            \"max_depth\": [2, 4, 8, 16],\n",
    "            \"min_samples_leaf\": [64, 128, 256],\n",
    "            \"learning_rate\": [0.15, 0.175, 0.2,],\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "samplers = [\n",
    "    {\n",
    "        \"name\": \"nearmiss\",\n",
    "        \"clf\": NearMiss(n_jobs=-1, n_neighbors_ver3=3,),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [3, 5],\n",
    "            \"sampling_strategy\": [\"majority\"],\n",
    "            'version': [2, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"randomundersampler\",\n",
    "        \"clf\": RandomUnderSampler(random_state=1729, replacement=False),\n",
    "        \"params\": {\n",
    "            \"sampling_strategy\": [\"majority\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"adasyn\",\n",
    "        \"clf\": ADASYN(n_jobs=-1, random_state=1729, ),\n",
    "        \"params\": {\n",
    "           \"sampling_strategy\": [\"auto\"],\n",
    "           \"n_neighbors\": [3, 5, 10],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"smote\",\n",
    "        \"clf\": SMOTE(n_jobs=-1, random_state=1729,),\n",
    "        \"params\": {\n",
    "            \"sampling_strategy\": [\"auto\"],\n",
    "            \"k_neighbors\": [3, 5, 10],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"randomoversampler\",\n",
    "        \"clf\": RandomOverSampler(random_state=1729),\n",
    "        \"params\": {\n",
    "           \"sampling_strategy\": [\"auto\"],\n",
    "           \"shrinkage\": [None],\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": make_scorer(balanced_accuracy_score),\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"average_precision\": make_scorer(average_precision_score)\n",
    "}\n",
    "\n",
    "# make_pipeline_imb(LogisticRegression()).get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(data, labels, pipelines):\n",
    "    results = []\n",
    "\n",
    "    # split data\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(data, labels, test_size=0.1, random_state=1729)\n",
    "    \n",
    "    for item in pipelines:\n",
    "        name, pipeline = item[\"name\"], item[\"pipeline\"]\n",
    "        # fit model\n",
    "        model = pipeline.fit(X_tr, y_tr)\n",
    "        \n",
    "        # predict\n",
    "        y_hat = model.predict(X_val)\n",
    "        \n",
    "        # get reports\n",
    "        target_names = [\"non-fraud\", \"fraud\"]\n",
    "        report = classification_report(y_val, y_hat, target_names=target_names)\n",
    "        report_imb = classification_report_imbalanced(y_val, y_hat, target_names=target_names)\n",
    "\n",
    "        # calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_hat)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_val, y_hat)\n",
    "        precision = precision_score(y_val, y_hat)\n",
    "        recall = recall_score(y_val, y_hat)\n",
    "        f1 = f1_score(y_val, y_hat)\n",
    "        roc_auc = roc_auc_score(y_val, y_hat)\n",
    "        ap_score = average_precision_score(y_val, y_hat)\n",
    "        \n",
    "        results.append({\n",
    "            \"name\": name,\n",
    "            \"model\": model,\n",
    "            \"eval\": {\n",
    "                \"report\": report,\n",
    "                \"report_imb\": report_imb,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"balanced_accuracy\": balanced_accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1,\n",
    "                \"roc_auc\": roc_auc,\n",
    "                \"avg_precision\": ap_score,\n",
    "            },\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def create_pipelines(classifiers, param_tune=False, cv_tuner=None, cv=None, scoring=None, refit=None):\n",
    "    pipelines = []\n",
    "    for item in classifiers:\n",
    "        clf = item[\"clf\"]\n",
    "        pipeline = make_pipeline(clf)\n",
    "        \n",
    "        grid = { f\"{item['name']}__{k}\":v for k,v in item[\"params\"].items()}\n",
    "        # grid = item[\"params\"]\n",
    "        \n",
    "        if param_tune:\n",
    "            pipeline = cv_tuner(pipeline, grid, cv=cv, n_jobs=-1, verbose=2, scoring=scoring, refit=refit)\n",
    "       \n",
    "        pipelines.append({\n",
    "            \"name\": item[\"name\"],\n",
    "            \"pipeline\": pipeline,\n",
    "            \"grid\": grid,\n",
    "        })\n",
    "    return pipelines\n",
    "\n",
    "def create_pipelines_with_sampler(samplers, classifiers, param_tune=False, cv_tuner=None, cv=None, scoring=None, refit=None):\n",
    "    pipelines = []\n",
    "    for item_c in classifiers:\n",
    "        for item_s in samplers:\n",
    "            pipeline = make_pipeline_imb(item_s[\"clf\"], item_c[\"clf\"])\n",
    "            \n",
    "            grid_s = { f\"{item_s['name']}__{k}\":v for k,v in item_s[\"params\"].items()}\n",
    "            grid_c = { f\"{item_c['name']}__{k}\":v for k,v in item_c[\"params\"].items()}\n",
    "            grid = {**grid_s, **grid_c}\n",
    "            # grid = {**item_s[\"params\"] , **item_c[\"params\"]}\n",
    "            \n",
    "            if param_tune:\n",
    "                pipeline = cv_tuner(pipeline, grid, cv=cv, n_jobs=-1, verbose=2, scoring=scoring, refit=refit)\n",
    "        \n",
    "            pipelines.append({\n",
    "                \"name\": f\"{item_c['name']}__{item_s['name']}\",\n",
    "                \"pipeline\": pipeline,\n",
    "                \"grid\": grid,\n",
    "            })\n",
    "    return pipelines\n",
    "\n",
    "\n",
    "def print_results(results, highlight=False):\n",
    "    results_df = []\n",
    "    for res in results:\n",
    "        item = {\n",
    "            \"name\": res[\"name\"],\n",
    "        }\n",
    "        item.update(res[\"eval\"])\n",
    "        results_df.append(item)\n",
    "\n",
    "    results_df = pd.DataFrame(results_df)\n",
    "    results_df.drop([\"report\", \"report_imb\"], axis=1, inplace=True)\n",
    "    if highlight:\n",
    "        return results_df.style.highlight_max(subset=results_df.columns[1:])\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def print_reports(results, idx):\n",
    "    print(f\"--- Classification Report ---\")\n",
    "    print(results[idx][\"eval\"][\"report\"])\n",
    "    \n",
    "    print(f\"--- Imbalanced Classification Report ---\")\n",
    "    print(results[idx][\"eval\"][\"report_imb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models - no sampling - without hyper-parameter tuning\n",
    "pipelines = create_pipelines(\n",
    "    classifiers, param_tune=False, cv_tuner=None\n",
    ")\n",
    "\n",
    "results_ns_nht = train_models(\n",
    "    data=X, labels=y, pipelines=pipelines,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualize\n",
    "results_ns_nht_df = print_results(results_ns_nht, highlight=False)\n",
    "results_ns_nht_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_reports(results_ns_nht, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train models - no sampling - with hyper-parameter tuning\n",
    "\n",
    "# param_tune=True\n",
    "# cv_tuner=RandomizedSearchCV\n",
    "# # cv_tuner=GridSearchCV\n",
    "# cv=3\n",
    "# refit=\"f1\"\n",
    "\n",
    "# pipelines = create_pipelines(\n",
    "#     classifiers, \n",
    "#     param_tune=param_tune, \n",
    "#     cv_tuner=cv_tuner, \n",
    "#     cv=cv, \n",
    "#     scoring=scoring, \n",
    "#     refit=refit\n",
    "# )\n",
    "\n",
    "# [item['name'] for item in pipelines]\n",
    "\n",
    "# results_ns_ht = train_models(\n",
    "#     data=X, labels=y, pipelines=pipelines,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vizualize\n",
    "# results_ns_ht_df = print_results(results_ns_ht, highlight=False)\n",
    "# results_ns_ht_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models - with sampling - without hyper-parameter tuning\n",
    "pipelines = create_pipelines_with_sampler(\n",
    "    samplers, classifiers, param_tune=False, cv_tuner=None\n",
    ")\n",
    "\n",
    "print(f\"pipelines: {[item['name'] for item in pipelines]}\")\n",
    "\n",
    "results_s_nht = train_models(\n",
    "    data=X, labels=y, pipelines=pipelines,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualize\n",
    "results_s_nht_df = print_results(results_s_nht, highlight=False)\n",
    "results_s_nht_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train models - with sampling - with hyper-parameter tuning\n",
    "# param_tune=True\n",
    "# cv_tuner=RandomizedSearchCV\n",
    "# # cv=3\n",
    "# cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "# refit=\"f1\"\n",
    "\n",
    "# pipelines = create_pipelines_with_sampler(\n",
    "#     samplers, \n",
    "#     classifiers, \n",
    "#     param_tune=param_tune, \n",
    "#     cv_tuner=cv_tuner, \n",
    "#     cv=cv, \n",
    "#     scoring=scoring, \n",
    "#     refit=refit\n",
    "# )\n",
    "\n",
    "# print(f\"pipelines: {[item['name'] for item in pipelines]}\")\n",
    "\n",
    "# results_s_ht = train_models(\n",
    "#     data=X, labels=y, pipelines=pipelines,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vizualize\n",
    "# results_s_ht_df = print_results(results_s_ht, highlight=False)\n",
    "# results_s_ht_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_reports(results_s_ht, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
